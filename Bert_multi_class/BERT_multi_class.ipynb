{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from tqdm import tqdm_notebook, trange\n",
    "import os\n",
    "from pytorch_pretrained_bert import BertConfig,BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tools import *\n",
    "import convert_examples_to_features\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input data dir. Should contain the .tsv files (or other data files) for the task.\n",
    "DATA_DIR = \"/home/xwan6/Bert_multi_class/\"\n",
    "\n",
    "# Bert pre-trained model selected in the list: bert-base-uncased, \n",
    "# bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased,\n",
    "# bert-base-multilingual-cased, bert-base-chinese.\n",
    "BERT_MODEL = 'bert-base-cased'\n",
    "\n",
    "# The name of the task to train.I'm going to name this 'yelp'.\n",
    "TASK_NAME = 'Task'\n",
    "\n",
    "# The output directory where the fine-tuned model and checkpoints will be written.\n",
    "OUTPUT_DIR = f'outputs/{TASK_NAME}/'\n",
    "\n",
    "# The directory where the evaluation reports will be written to.\n",
    "REPORTS_DIR = f'reports/{TASK_NAME}_evaluation_report/'\n",
    "\n",
    "# This is where BERT will look for pre-trained models to load parameters from.\n",
    "CACHE_DIR = 'cache/'\n",
    "\n",
    "# The maximum total input sequence length after WordPiece tokenization.\n",
    "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "TRAIN_BATCH_SIZE = 24\n",
    "EVAL_BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "RANDOM_SEED = 42\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "WARMUP_PROPORTION = 0.1\n",
    "OUTPUT_MODE = 'classification'\n",
    "\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick example\n",
    "import pandas as pd\n",
    "train_data = [\n",
    "    [\"Example sentence belonging to class 1\", 1],\n",
    "    [\"Example sentence belonging to class 0\", 0],\n",
    "    [\"Example eval senntence belonging to class 2\", 2],\n",
    "]\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "test_df = [\n",
    "    [\"Example eval sentence belonging to class 1\", 1],\n",
    "    [\"Example eval sentence belonging to class 0\", 0],\n",
    "    [\"Example eval senntence belonging to class 2\", 2],\n",
    "]\n",
    "\n",
    "test_df = pd.DataFrame(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>here is reason's why there been a lack of yout...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>So far, so good. 0-3. Borehamwood, close to my...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>construction on 12th Street eastbound between ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Cleanup after a big rig fire. two right lanes ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Construction on 320Bus Both directions from Mi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  here is reason's why there been a lack of yout...  5\n",
       "1  So far, so good. 0-3. Borehamwood, close to my...  5\n",
       "2  construction on 12th Street eastbound between ...  1\n",
       "3  Cleanup after a big rig fire. two right lanes ...  3\n",
       "4  Construction on 320Bus Both directions from Mi...  4"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('train.csv',header=None)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I-80 WB: Right lane closed between Exit 128 - ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Turnpike Roadwork on I-476 PA Turnpike southbo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lmfao yall really mentioned chrome, the nugget...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Between Jordanstown and Whiteabbey : Road Traf...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CLEARED: Crash on US 22 westbound between US 2...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  I-80 WB: Right lane closed between Exit 128 - ...  3\n",
       "1  Turnpike Roadwork on I-476 PA Turnpike southbo...  1\n",
       "2  lmfao yall really mentioned chrome, the nugget...  5\n",
       "3  Between Jordanstown and Whiteabbey : Road Traf...  3\n",
       "4  CLEARED: Crash on US 22 westbound between US 2...  4"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv', header=None)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>alpha</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>here is reason's why there been a lack of yout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>So far, so good. 0-3. Borehamwood, close to my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>construction on 12th Street eastbound between ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>Cleanup after a big rig fire. two right lanes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>Construction on 320Bus Both directions from Mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label alpha                                               text\n",
       "0   0      5     a  here is reason's why there been a lack of yout...\n",
       "1   1      5     a  So far, so good. 0-3. Borehamwood, close to my...\n",
       "2   2      1     a  construction on 12th Street eastbound between ...\n",
       "3   3      3     a  Cleanup after a big rig fire. two right lanes ...\n",
       "4   4      4     a  Construction on 320Bus Both directions from Mi..."
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change data to tsv form (for BERT Input)\n",
    "train_df_bert = pd.DataFrame({\n",
    "    'id':range(len(train_df)),\n",
    "    'label':train_df[1],\n",
    "    'alpha':['a']*train_df.shape[0],\n",
    "    'text': train_df[0].replace(r'\\n', ' ', regex=True)\n",
    "})\n",
    "\n",
    "train_df_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>alpha</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>I-80 WB: Right lane closed between Exit 128 - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>Turnpike Roadwork on I-476 PA Turnpike southbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>lmfao yall really mentioned chrome, the nugget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>Between Jordanstown and Whiteabbey : Road Traf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>CLEARED: Crash on US 22 westbound between US 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label alpha                                               text\n",
       "0   0      3     a  I-80 WB: Right lane closed between Exit 128 - ...\n",
       "1   1      1     a  Turnpike Roadwork on I-476 PA Turnpike southbo...\n",
       "2   2      5     a  lmfao yall really mentioned chrome, the nugget...\n",
       "3   3      3     a  Between Jordanstown and Whiteabbey : Road Traf...\n",
       "4   4      4     a  CLEARED: Crash on US 22 westbound between US 2..."
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df_bert = pd.DataFrame({\n",
    "    'id':range(len(test_df)),\n",
    "    'label':test_df[1],\n",
    "    'alpha':['a']*test_df.shape[0],\n",
    "    'text': test_df[0].replace(r'\\n', ' ', regex=True)\n",
    "})\n",
    "\n",
    "dev_df_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the train and dev data as .tsv files.\n",
    "train_df_bert.to_csv('train.tsv', sep='\\t', index=False, header=False)\n",
    "dev_df_bert.to_csv('dev.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2147483647"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "csv.field_size_limit(2147483647) # Increase CSV reader's field limit incase we have long text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "\n",
    "        \"\"\"Constructs a InputExample.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "\n",
    "    def get_labels(self):\n",
    "\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "\n",
    "            lines = []\n",
    "\n",
    "            for line in reader:\n",
    "\n",
    "                if sys.version_info[0] == 2:\n",
    "\n",
    "                    line = list(unicode(cell, 'utf-8') for cell in line)\n",
    "\n",
    "                lines.append(line)\n",
    "\n",
    "            return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationProcessor(DataProcessor):\n",
    "\n",
    "    \"\"\"Processor for binary classification dataset.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "\n",
    "        \"\"\"See base class.\"\"\"\n",
    "\n",
    "        return self._create_examples(\n",
    "\n",
    "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "\n",
    "        \"\"\"See base class.\"\"\"\n",
    "\n",
    "        return self._create_examples(\n",
    "\n",
    "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "\n",
    "\n",
    "    def get_labels(self):\n",
    "\n",
    "        \"\"\"See base class.\"\"\"\n",
    "\n",
    "        return [\"0\", \"1\", \"2\",\"3\",\"4\",\"5\"]\n",
    "\n",
    "\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "\n",
    "        examples = []\n",
    "        lines = pd.DataFrame(lines)\n",
    "        # not that the number 1,3 related to the order of where you put the label and text in the origianl dataset\n",
    "        for i, line in enumerate(zip(lines.iloc[:,1],lines.iloc[:,3])):\n",
    "\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "\n",
    "            text_a = line[1]\n",
    "\n",
    "            label = line[0]\n",
    "\n",
    "            examples.append(\n",
    "\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "\n",
    "        self.input_ids = input_ids\n",
    "\n",
    "        self.input_mask = input_mask\n",
    "\n",
    "        self.segment_ids = segment_ids\n",
    "\n",
    "        self.label_id = label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "\n",
    "    while True:\n",
    "\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "\n",
    "        if total_length <= max_length:\n",
    "\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "\n",
    "            tokens_a.pop()\n",
    "\n",
    "        else:\n",
    "\n",
    "            tokens_b.pop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_to_feature(example_row):\n",
    "\n",
    "    # return example_row\n",
    "\n",
    "    example, label_map, max_seq_length, tokenizer, output_mode = example_row\n",
    "\n",
    "\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "\n",
    "\n",
    "    tokens_b = None\n",
    "\n",
    "    if example.text_b:\n",
    "\n",
    "        tokens_b = tokenizer.tokenize(example.text_b)\n",
    "\n",
    "        # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "\n",
    "        # length is less than the specified length.\n",
    "\n",
    "        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "\n",
    "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Account for [CLS] and [SEP] with \"- 2\"\n",
    "\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "\n",
    "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "\n",
    "\n",
    "    tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "\n",
    "    segment_ids = [0] * len(tokens)\n",
    "\n",
    "\n",
    "\n",
    "    if tokens_b:\n",
    "\n",
    "        tokens += tokens_b + [\"[SEP]\"]\n",
    "\n",
    "        segment_ids += [1] * (len(tokens_b) + 1)\n",
    "\n",
    "\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "\n",
    "    # tokens are attended to.\n",
    "\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "\n",
    "    padding = [0] * (max_seq_length - len(input_ids))\n",
    "\n",
    "    input_ids += padding\n",
    "\n",
    "    input_mask += padding\n",
    "\n",
    "    segment_ids += padding\n",
    "\n",
    "\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "\n",
    "    assert len(input_mask) == max_seq_length\n",
    "\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "\n",
    "\n",
    "    if output_mode == \"classification\":\n",
    "\n",
    "        label_id = label_map[example.label]\n",
    "\n",
    "    elif output_mode == \"regression\":\n",
    "\n",
    "        label_id = float(example.label)\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise KeyError(output_mode)\n",
    "\n",
    "\n",
    "\n",
    "    return InputFeatures(input_ids=input_ids,\n",
    "\n",
    "                         input_mask=input_mask,\n",
    "\n",
    "                         segment_ids=segment_ids,\n",
    "\n",
    "                         label_id=label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input data dir. Should contain the .tsv files (or other data files) for the task.\n",
    "DATA_DIR = \"/home/xwan6/Bert_multi_class/\"\n",
    "\n",
    "# Bert pre-trained model selected in the list: bert-base-uncased, \n",
    "# bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased,\n",
    "# bert-base-multilingual-cased, bert-base-chinese.\n",
    "BERT_MODEL = 'bert-base-cased'\n",
    "\n",
    "# The name of the task to train.I'm going to name this 'yelp'.\n",
    "TASK_NAME = 'Task'\n",
    "\n",
    "# The output directory where the fine-tuned model and checkpoints will be written.\n",
    "OUTPUT_DIR = f'outputs/{TASK_NAME}/'\n",
    "\n",
    "# The directory where the evaluation reports will be written to.\n",
    "REPORTS_DIR = f'reports/{TASK_NAME}_evaluation_report/'\n",
    "\n",
    "# This is where BERT will look for pre-trained models to load parameters from.\n",
    "CACHE_DIR = 'cache/'\n",
    "\n",
    "# The maximum total input sequence length after WordPiece tokenization.\n",
    "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "TRAIN_BATCH_SIZE = 24\n",
    "EVAL_BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "RANDOM_SEED = 42\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "WARMUP_PROPORTION = 0.1\n",
    "OUTPUT_MODE = 'classification'\n",
    "\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mode = OUTPUT_MODE\n",
    "cache_dir = CACHE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(REPORTS_DIR) and os.listdir(REPORTS_DIR):\n",
    "        REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
    "        os.makedirs(REPORTS_DIR)\n",
    "if not os.path.exists(REPORTS_DIR):\n",
    "    os.makedirs(REPORTS_DIR)\n",
    "    REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
    "    os.makedirs(REPORTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(OUTPUT_DIR) and os.listdir(OUTPUT_DIR):\n",
    "        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(OUTPUT_DIR))\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ClassificationProcessor()\n",
    "train_examples = processor.get_train_examples(DATA_DIR)\n",
    "train_examples_len = len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = processor.get_labels() # [0, 1] for binary classification # [0,1,2,3,4,5] for multiclassification\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5']"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_optimization_steps = int(\n",
    "    train_examples_len / TRAIN_BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS) * NUM_TRAIN_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/xwan6/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "train_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in train_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to convert 36775 examples..\n",
      "Spawning 31 processes..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb003c8f2b2046fd80fda8c6c77abf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36775), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# process the examples with multiple cpu (slightly fast)\n",
    "process_count = cpu_count() - 1\n",
    "if __name__ ==  '__main__':\n",
    "    print(f'Preparing to convert {train_examples_len} examples..')\n",
    "    print(f'Spawning {process_count} processes..')\n",
    "    with Pool(process_count) as p:\n",
    "        train_features = list(tqdm_notebook(p.imap(convert_examples_to_features.convert_example_to_feature, train_examples_for_processing), total=train_examples_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle\n",
    "with open(DATA_DIR + \"train_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open pickle\n",
    "with open(DATA_DIR + \"train_features.pkl\", \"rb\") as f:\n",
    "    train_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz from cache at cache/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file cache/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c to temp dir /tmp/tmp85jyj6_4\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, cache_dir=CACHE_DIR, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the default parameters\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=LEARNING_RATE,\n",
    "                     warmup=WARMUP_PROPORTION,\n",
    "                     t_total=num_train_optimization_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:***** Running training *****\n",
      "INFO:root:  Num examples = 36775\n",
      "INFO:root:  Batch size = 24\n",
      "INFO:root:  Num steps = 1532\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", train_examples_len)\n",
    "logger.info(\"  Batch size = %d\", TRAIN_BATCH_SIZE)\n",
    "logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "\n",
    "if OUTPUT_MODE == \"classification\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "elif OUTPUT_MODE == \"regression\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up our DataLoader for training..\n",
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7214077f8f4f4722b1c9793b6666bb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=1533, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 100%|██████████| 1/1 [22:30<00:00, 1350.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training time\n",
    "model.train()\n",
    "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
    "    loss_record = []\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm_notebook(train_dataloader, desc=\"Iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
    "\n",
    "        if OUTPUT_MODE == \"classification\":\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "        elif OUTPUT_MODE == \"regression\":\n",
    "            loss_fct = MSELoss()\n",
    "            loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
    "\n",
    "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "        loss.backward()\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "        # get the loss for each steps\n",
    "        loss_record.append(loss.item())\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_record[:5000])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/xwan6/Bert_multi_class/outputs/Task/vocab.txt'"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "# If we save using the predefined names, we can load using `from_pretrained`\n",
    "output_model_file = os.path.join(OUTPUT_DIR, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(OUTPUT_DIR, CONFIG_NAME)\n",
    "\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "tokenizer.save_vocabulary(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from tools import *\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import convert_examples_to_features\n",
    "\n",
    "from tqdm import tqdm_notebook, trange\n",
    "import os\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input data dir. Should contain the .tsv files (or other data files) for the task.\n",
    "DATA_DIR = \"/home/xwan6/Bert_multi_class/\"\n",
    "\n",
    "# Bert pre-trained model selected in the list: bert-base-uncased, \n",
    "# bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased,\n",
    "# bert-base-multilingual-cased, bert-base-chinese.\n",
    "#BERT_MODEL = 'bert-base-cased'\n",
    "\n",
    "# The name of the task to train.I'm going to name this 'yelp'.\n",
    "TASK_NAME = 'Task'\n",
    "\n",
    "# The output directory where the fine-tuned model and checkpoints will be written.\n",
    "OUTPUT_DIR = '/home/xwan6/Bert_multi_class/outputs/Task/'\n",
    "\n",
    "# The directory where the evaluation reports will be written to.\n",
    "REPORTS_DIR = '/home/xwan6/Bert_multi_class/reports/Task_evaluation_reports/'\n",
    "\n",
    "# This is where BERT will look for pre-trained models to load parameters from.\n",
    "CACHE_DIR = 'cache/'\n",
    "\n",
    "# The maximum total input sequence length after WordPiece tokenization.\n",
    "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "TRAIN_BATCH_SIZE = 24\n",
    "EVAL_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "RANDOM_SEED = 42\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "WARMUP_PROPORTION = 0.1\n",
    "OUTPUT_MODE = 'classification'\n",
    "\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(REPORTS_DIR) and os.listdir(REPORTS_DIR):\n",
    "        REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
    "        os.makedirs(REPORTS_DIR)\n",
    "if not os.path.exists(REPORTS_DIR):\n",
    "    os.makedirs(REPORTS_DIR)\n",
    "    REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
    "    os.makedirs(REPORTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we must remove wrap cell in the csv in order to process\n",
    "processor = ClassificationProcessor()\n",
    "eval_examples = processor.get_dev_examples(DATA_DIR)\n",
    "label_list = processor.get_labels() # [0, 1] for binary classification\n",
    "num_labels = len(label_list)\n",
    "eval_examples_len = len(eval_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "eval_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in eval_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to convert 3500 examples..\n",
      "Spawning 31 processes..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41d7960234d4007bd28d654375db9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_count = cpu_count() - 1\n",
    "if __name__ ==  '__main__':\n",
    "    print(f'Preparing to convert {eval_examples_len} examples..')\n",
    "    print(f'Spawning {process_count} processes..')\n",
    "    with Pool(process_count) as p:\n",
    "        eval_features = list(tqdm_notebook(p.imap(convert_examples_to_features.convert_example_to_feature, eval_examples_for_processing), total=eval_examples_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OUTPUT_MODE == \"classification\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "elif OUTPUT_MODE == \"regression\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "# Run prediction for full data\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz not found in cache, downloading to /tmp/tmpf3jacc0g\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/404400730 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 382976/404400730 [00:00<01:45, 3814421.57B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 852992/404400730 [00:00<01:40, 4031670.36B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1427456/404400730 [00:00<01:31, 4420081.43B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 2158592/404400730 [00:00<01:20, 4992819.89B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 2785280/404400730 [00:00<01:15, 5295133.12B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 3446784/404400730 [00:00<01:11, 5618520.59B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 4282368/404400730 [00:00<01:04, 6204456.67B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏         | 5161984/404400730 [00:00<00:58, 6804218.52B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 6127616/404400730 [00:00<00:53, 7434866.30B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 7147520/404400730 [00:01<00:49, 8092741.14B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 8042496/404400730 [00:01<00:47, 8308536.31B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 9079808/404400730 [00:01<00:44, 8835936.42B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 10148864/404400730 [00:01<00:42, 9286429.68B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 11343872/404400730 [00:01<00:39, 9951904.60B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 12725248/404400730 [00:01<00:36, 10836401.58B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▎         | 14325760/404400730 [00:01<00:32, 11998409.45B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 15973376/404400730 [00:01<00:29, 13062809.13B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 17586176/404400730 [00:01<00:27, 13851692.47B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▍         | 19052544/404400730 [00:01<00:27, 14083774.92B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 20509696/404400730 [00:02<00:28, 13506804.57B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 21943296/404400730 [00:02<00:27, 13744572.73B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 23346176/404400730 [00:02<00:27, 13748396.62B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 25102336/404400730 [00:02<00:25, 14692273.72B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 26990592/404400730 [00:02<00:23, 15739842.26B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 28879872/404400730 [00:02<00:22, 16451085.11B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 30905344/404400730 [00:02<00:21, 17432409.41B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 32692224/404400730 [00:02<00:21, 17538897.49B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▊         | 34859008/404400730 [00:02<00:19, 18600923.11B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 37005312/404400730 [00:02<00:18, 19360172.00B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|▉         | 38976512/404400730 [00:03<00:20, 17881506.84B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 41245696/404400730 [00:03<00:19, 19095743.14B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|█         | 43768832/404400730 [00:03<00:17, 20597453.19B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|█▏        | 46195712/404400730 [00:03<00:16, 21514134.67B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 48409600/404400730 [00:03<00:16, 21601778.50B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 50802688/404400730 [00:03<00:15, 22251420.61B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 53241856/404400730 [00:03<00:15, 22852985.44B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▎        | 55575552/404400730 [00:03<00:15, 22994539.91B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 58264576/404400730 [00:03<00:14, 24038396.76B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 60695552/404400730 [00:03<00:14, 23848441.03B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 64010240/404400730 [00:04<00:13, 26039729.85B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 67525632/404400730 [00:04<00:11, 28234388.50B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 71403520/404400730 [00:04<00:10, 30741056.56B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 74730496/404400730 [00:04<00:10, 31455777.57B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|█▉        | 78423040/404400730 [00:04<00:09, 32918482.07B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 81804288/404400730 [00:04<00:09, 33106953.30B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|██        | 85178368/404400730 [00:04<00:10, 29919062.88B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 88272896/404400730 [00:04<00:13, 22699047.57B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 90874880/404400730 [00:05<00:14, 20905667.73B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 93225984/404400730 [00:05<00:16, 19361058.07B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|██▎       | 95367168/404400730 [00:05<00:18, 17035793.56B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|██▍       | 97265664/404400730 [00:05<00:18, 16857894.37B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▍       | 99088384/404400730 [00:05<00:17, 16981862.68B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▍       | 100966400/404400730 [00:05<00:17, 17316203.07B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 102968320/404400730 [00:05<00:16, 18046659.67B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 105093120/404400730 [00:05<00:15, 18900140.21B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 107033600/404400730 [00:06<00:16, 17726780.54B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 109127680/404400730 [00:06<00:15, 18582293.69B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 111139840/404400730 [00:06<00:15, 19018137.98B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 113483776/404400730 [00:06<00:14, 20033985.31B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▊       | 115886080/404400730 [00:06<00:13, 21080898.70B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▉       | 118036480/404400730 [00:06<00:13, 21186529.96B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|██▉       | 120576000/404400730 [00:06<00:12, 22294734.27B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 123234304/404400730 [00:06<00:12, 23427521.85B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███       | 126052352/404400730 [00:06<00:11, 24673085.73B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 129261568/404400730 [00:06<00:10, 26510852.70B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 132217856/404400730 [00:07<00:09, 27356501.08B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 135364608/404400730 [00:07<00:09, 28393247.36B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|███▍      | 138254336/404400730 [00:07<00:09, 27434994.45B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 142561280/404400730 [00:07<00:08, 30787202.52B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 145803264/404400730 [00:07<00:09, 28600186.20B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 148808704/404400730 [00:07<00:09, 26968307.31B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 151626752/404400730 [00:07<00:10, 24906966.53B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 154233856/404400730 [00:07<00:10, 23143917.32B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███▊      | 156654592/404400730 [00:07<00:11, 22294748.44B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███▉      | 158965760/404400730 [00:08<00:11, 21376015.48B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███▉      | 161168384/404400730 [00:08<00:11, 21297762.78B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 163344384/404400730 [00:08<00:11, 20752107.83B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████      | 165454848/404400730 [00:08<00:11, 20577034.18B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 167537664/404400730 [00:08<00:11, 20463567.86B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████▏     | 169602048/404400730 [00:08<00:11, 20291890.88B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████▏     | 171660288/404400730 [00:08<00:11, 20326982.57B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 173702144/404400730 [00:08<00:11, 20209015.46B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████▍     | 179321856/404400730 [00:08<00:08, 25014485.59B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 182427648/404400730 [00:09<00:12, 18120112.87B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 184932352/404400730 [00:09<00:11, 18733429.68B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▋     | 187295744/404400730 [00:09<00:11, 19237519.09B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 189656064/404400730 [00:09<00:10, 20367129.37B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 192027648/404400730 [00:09<00:09, 21248745.54B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|████▊     | 194378752/404400730 [00:09<00:09, 21725987.07B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|████▊     | 197091328/404400730 [00:09<00:08, 23105365.77B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 199522304/404400730 [00:10<00:11, 17257594.06B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|████▉     | 201549824/404400730 [00:10<00:11, 17405239.58B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████     | 205623296/404400730 [00:10<00:09, 21000974.78B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 208768000/404400730 [00:10<00:08, 23324485.74B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 211538944/404400730 [00:10<00:07, 24486375.48B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 214296576/404400730 [00:10<00:08, 22299653.25B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████▎    | 216780800/404400730 [00:10<00:08, 22682144.66B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████▍    | 219296768/404400730 [00:10<00:08, 23004801.33B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▍    | 221724672/404400730 [00:10<00:07, 23299254.08B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████▌    | 224457728/404400730 [00:11<00:07, 24086278.02B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████▌    | 227111936/404400730 [00:11<00:07, 24773846.91B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 229643264/404400730 [00:11<00:07, 24581147.70B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 232431616/404400730 [00:11<00:06, 24927110.40B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████▊    | 235083776/404400730 [00:11<00:06, 25383469.12B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████▉    | 237643776/404400730 [00:11<00:06, 25132793.23B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████▉    | 240367616/404400730 [00:11<00:06, 25729037.14B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 242955264/404400730 [00:11<00:06, 25426100.14B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|██████    | 245509120/404400730 [00:11<00:06, 24948193.09B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 249629696/404400730 [00:11<00:05, 28296206.73B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 252618752/404400730 [00:12<00:05, 28058049.90B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 255537152/404400730 [00:12<00:05, 27356308.65B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|██████▍   | 259460096/404400730 [00:12<00:04, 30087084.55B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▌   | 263249920/404400730 [00:12<00:04, 32068961.05B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████▌   | 267107328/404400730 [00:12<00:04, 33774914.25B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 271070208/404400730 [00:12<00:03, 35338619.44B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 275290112/404400730 [00:12<00:03, 37046092.46B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████▉   | 279554048/404400730 [00:12<00:03, 38562695.38B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 284218368/404400730 [00:12<00:02, 40522379.60B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████▏  | 288809984/404400730 [00:13<00:02, 42001314.94B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 293082112/404400730 [00:13<00:02, 41700745.33B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▎  | 297303040/404400730 [00:13<00:03, 29516849.40B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 300784640/404400730 [00:13<00:04, 22220953.20B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 303644672/404400730 [00:13<00:05, 20073794.34B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████▌  | 306138112/404400730 [00:13<00:04, 19677264.84B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████▋  | 308448256/404400730 [00:14<00:05, 16335141.30B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 310578176/404400730 [00:14<00:05, 17562820.38B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 312845312/404400730 [00:14<00:04, 18835848.69B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 315154432/404400730 [00:14<00:04, 19899673.57B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|███████▊  | 317486080/404400730 [00:14<00:04, 20813555.95B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|███████▉  | 320093184/404400730 [00:14<00:03, 22153782.09B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████▉  | 322831360/404400730 [00:14<00:03, 23486896.16B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|████████  | 325573632/404400730 [00:14<00:03, 24542743.34B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|████████  | 328512512/404400730 [00:14<00:02, 25818629.60B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████▏ | 331447296/404400730 [00:15<00:02, 26782736.41B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 334683136/404400730 [00:15<00:02, 28241525.58B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▎ | 337772544/404400730 [00:15<00:02, 28987157.73B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 340848640/404400730 [00:15<00:02, 29496174.06B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 344573952/404400730 [00:15<00:01, 31393495.65B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 347772928/404400730 [00:15<00:01, 31222219.45B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 350937088/404400730 [00:15<00:01, 29326909.17B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 353923072/404400730 [00:15<00:01, 29122049.83B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 356873216/404400730 [00:15<00:01, 28372481.25B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████▉ | 359741440/404400730 [00:15<00:01, 28351690.64B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|████████▉ | 362598400/404400730 [00:16<00:01, 28131072.69B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 365427712/404400730 [00:16<00:01, 25400454.58B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 368029696/404400730 [00:16<00:01, 21796905.13B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 370519040/404400730 [00:16<00:01, 22641700.20B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 373114880/404400730 [00:16<00:01, 23544161.28B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 375789568/404400730 [00:16<00:01, 24420666.16B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|█████████▎| 378296320/404400730 [00:16<00:01, 24090899.46B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|█████████▍| 380751872/404400730 [00:16<00:01, 23216854.99B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████▍| 383113216/404400730 [00:16<00:00, 23062471.09B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████▌| 385447936/404400730 [00:17<00:00, 22530842.40B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████▌| 387978240/404400730 [00:17<00:00, 23296236.50B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 390330368/404400730 [00:17<00:00, 23061216.68B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 392652800/404400730 [00:17<00:00, 22248719.56B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████▊| 394895360/404400730 [00:17<00:00, 22004782.41B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████▊| 397109248/404400730 [00:17<00:00, 21768964.59B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 399496192/404400730 [00:17<00:00, 22334673.21B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████▉| 401853440/404400730 [00:17<00:00, 22691965.94B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 404400730/404400730 [00:17<00:00, 22556558.53B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmpf3jacc0g to cache at cache/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n",
      "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for cache/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n",
      "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmpf3jacc0g\n",
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz from cache at cache/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file cache/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c to temp dir /tmp/tmpuy6hsb5c\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pre-trained model (weights)\n",
    "#model = BertForSequenceClassification.from_pretrained(BERT_MODEL, cache_dir=CACHE_DIR, num_labels=len(label_list))\n",
    "# d = torch.load(output_model_file)\n",
    "#model.load_state_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e494606bdc244e009e429b3b5b7530b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=438, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "preds = []\n",
    "\n",
    "for input_ids, input_mask, segment_ids, label_ids in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    label_ids = label_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
    "\n",
    "    # create eval loss and other metric required by the task\n",
    "    if OUTPUT_MODE == \"classification\":\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        tmp_eval_loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "    elif OUTPUT_MODE == \"regression\":\n",
    "        loss_fct = MSELoss()\n",
    "        tmp_eval_loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
    "\n",
    "    eval_loss += tmp_eval_loss.mean().item()\n",
    "    nb_eval_steps += 1\n",
    "    if len(preds) == 0:\n",
    "        preds.append(logits.detach().cpu().numpy())\n",
    "    else:\n",
    "        preds[0] = np.append(\n",
    "            preds[0], logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "eval_loss = eval_loss / nb_eval_steps\n",
    "preds = preds[0]\n",
    "if OUTPUT_MODE == \"classification\":\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "elif OUTPUT_MODE == \"regression\":\n",
    "    preds = np.squeeze(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[575,   0,   0,   0,   2,   0],\n",
       "       [  0, 596,   0,   0,   0,   1],\n",
       "       [  0,   0, 597,   0,   1,   1],\n",
       "       [  0,   0,   0, 570,   0,   1],\n",
       "       [  0,   0,   0,   0, 567,   0],\n",
       "       [  0,   0,   0,   0,   0, 589]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(preds,all_label_ids.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(confusion_matrix(preds,all_label_ids.numpy()));\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9982857142857143"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds,all_label_ids.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>alpha</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>Stay in your lane!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>Lol stay in your lane. Talk about sports or so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>If we're going to have a low-key psycho occupy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>im 04 and im not outta pocket i stay in my lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>Double lane violation creates a jump ball so y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label alpha                                               text\n",
       "0   0      0     a                                 Stay in your lane!\n",
       "1   1      0     a  Lol stay in your lane. Talk about sports or so...\n",
       "2   2      0     a  If we're going to have a low-key psycho occupy...\n",
       "3   3      0     a  im 04 and im not outta pocket i stay in my lan...\n",
       "4   4      0     a  Double lane violation creates a jump ball so y..."
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we use our model to classify crowd-sourced information\n",
    "import pandas as pd\n",
    "test_df = pd.read_csv('example.csv')\n",
    "# change data to tsv form (for BERT Input)\n",
    "test_df_bert = pd.DataFrame({\n",
    "    'id':range(len(test_df)),\n",
    "    'label':[0]*test_df.shape[0],\n",
    "    'alpha':['a']*test_df.shape[0],\n",
    "    'text': test_df['text'].replace(r'\\n', ' ', regex=True)\n",
    "})\n",
    "test_df_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the test data as .tsv files.\n",
    "test_df_bert.to_csv('dev.tsv', sep='\\t', index=False, header=False)\n",
    "processor = BinaryClassificationProcessor()\n",
    "eval_examples = processor.get_dev_examples(DATA_DIR)\n",
    "label_list = processor.get_labels() # [0, 1] for binary classification\n",
    "num_labels = len(label_list)\n",
    "eval_examples_len = len(eval_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to convert 9902 examples..\n",
      "Spawning 31 processes..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbe4bd82f924591b3e35fbc507bde31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9902), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "eval_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in eval_examples]\n",
    "\n",
    "process_count = cpu_count() - 1\n",
    "if __name__ ==  '__main__':\n",
    "    print(f'Preparing to convert {eval_examples_len} examples..')\n",
    "    print(f'Spawning {process_count} processes..')\n",
    "    with Pool(process_count) as p:\n",
    "        eval_features = list(tqdm_notebook(p.imap(convert_examples_to_features.convert_example_to_feature, eval_examples_for_processing), total=eval_examples_len))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "\n",
    "if OUTPUT_MODE == \"classification\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "elif OUTPUT_MODE == \"regression\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "# Run prediction for full data\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6dffd1efdc4bf4824b6238aa653232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=1238, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "preds = []\n",
    "\n",
    "for input_ids, input_mask, segment_ids, label_ids in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
    "\n",
    "    if len(preds) == 0:\n",
    "        preds.append(logits.detach().cpu().numpy())\n",
    "    else:\n",
    "        preds[0] = np.append(\n",
    "            preds[0], logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "preds = preds[0]\n",
    "if OUTPUT_MODE == \"classification\":\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "elif OUTPUT_MODE == \"regression\":\n",
    "    preds = np.squeeze(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(preds)\n",
    "test_df['label'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = []\n",
    "for i in range(len(test_df)):\n",
    "    label = test_df.iloc[i]['label']\n",
    "    if label < 5:\n",
    "        row.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.iloc[row].to_csv('a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for one sentence\n",
    "text = 'I will visit the transportation office tomorrow at Garden parkay but my car is crashed.'\n",
    "#text = 'An accident on 73 SB approaching Fellowship Rd is causing a delay between 295 and the NJ Turnpike.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ex = []\n",
    "for i in range(10):\n",
    "    eval_ex.append(InputExample('1',text,None,'0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ex_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in eval_ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to convert 1 examples..\n",
      "Spawning 31 processes..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76106d96a22f43a1a8f679286707ab04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "process_count = cpu_count() - 1\n",
    "if __name__ ==  '__main__':\n",
    "    print(f'Preparing to convert {1} examples..')\n",
    "    print(f'Spawning {process_count} processes..')\n",
    "    with Pool(process_count) as p:\n",
    "        eval_features = list(tqdm_notebook(p.imap(convert_examples_to_features.convert_example_to_feature, eval_ex_for_processing), total=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "# Run prediction for full data\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53170ac7d49c45b58b3183416e9b19e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=2, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "preds = []\n",
    "\n",
    "for input_ids, input_mask, segment_ids, label_ids in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
    "    if len(preds) == 0:\n",
    "        preds.append(logits.detach().cpu().numpy())\n",
    "    else:\n",
    "        preds[0] = np.append(\n",
    "            preds[0], logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "preds = preds[0]\n",
    "preds = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
