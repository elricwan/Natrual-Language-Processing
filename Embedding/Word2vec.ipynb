{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/xwan6/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the raw data\n",
    "import itertools\n",
    "corpus = []\n",
    "for cat in ['news']:\n",
    "    for text_id in brown.fileids(cat):\n",
    "        raw_text = list(itertools.chain.from_iterable(brown.sents(text_id)))\n",
    "        text = ' '.join(raw_text)\n",
    "        text = text.lower()\n",
    "        text.replace('\\n', ' ')\n",
    "        text = re.sub('[^a-z ]+', '', text)\n",
    "        corpus.append([w for w in text.split() if w != ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'fulton',\n",
       " 'county',\n",
       " 'grand',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'friday',\n",
       " 'an',\n",
       " 'investigation',\n",
       " 'of',\n",
       " 'atlantas',\n",
       " 'recent',\n",
       " 'primary',\n",
       " 'election',\n",
       " 'produced',\n",
       " 'no',\n",
       " 'evidence',\n",
       " 'that',\n",
       " 'any',\n",
       " 'irregularities',\n",
       " 'took',\n",
       " 'place',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'further',\n",
       " 'said',\n",
       " 'in',\n",
       " 'termend',\n",
       " 'presentments',\n",
       " 'that',\n",
       " 'the',\n",
       " 'city',\n",
       " 'executive',\n",
       " 'committee',\n",
       " 'which',\n",
       " 'had',\n",
       " 'overall',\n",
       " 'charge',\n",
       " 'of',\n",
       " 'the',\n",
       " 'election',\n",
       " 'deserves',\n",
       " 'the',\n",
       " 'praise',\n",
       " 'and',\n",
       " 'thanks',\n",
       " 'of',\n",
       " 'the',\n",
       " 'city',\n",
       " 'of',\n",
       " 'atlanta',\n",
       " 'for',\n",
       " 'the',\n",
       " 'manner',\n",
       " 'in',\n",
       " 'which',\n",
       " 'the',\n",
       " 'election',\n",
       " 'was',\n",
       " 'conducted',\n",
       " 'the',\n",
       " 'septemberoctober',\n",
       " 'term',\n",
       " 'jury',\n",
       " 'had',\n",
       " 'been',\n",
       " 'charged',\n",
       " 'by',\n",
       " 'fulton',\n",
       " 'superior',\n",
       " 'court',\n",
       " 'judge',\n",
       " 'durwood',\n",
       " 'pye',\n",
       " 'to',\n",
       " 'investigate',\n",
       " 'reports',\n",
       " 'of',\n",
       " 'possible',\n",
       " 'irregularities',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hardfought',\n",
       " 'primary',\n",
       " 'which',\n",
       " 'was',\n",
       " 'won',\n",
       " 'by',\n",
       " 'mayornominate',\n",
       " 'ivan',\n",
       " 'allen',\n",
       " 'jr',\n",
       " 'only',\n",
       " 'a',\n",
       " 'relative',\n",
       " 'handful',\n",
       " 'of',\n",
       " 'such',\n",
       " 'reports',\n",
       " 'was',\n",
       " 'received',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'considering',\n",
       " 'the',\n",
       " 'widespread',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'the',\n",
       " 'election',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'voters',\n",
       " 'and',\n",
       " 'the',\n",
       " 'size',\n",
       " 'of',\n",
       " 'this',\n",
       " 'city',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'it',\n",
       " 'did',\n",
       " 'find',\n",
       " 'that',\n",
       " 'many',\n",
       " 'of',\n",
       " 'georgias',\n",
       " 'registration',\n",
       " 'and',\n",
       " 'election',\n",
       " 'laws',\n",
       " 'are',\n",
       " 'outmoded',\n",
       " 'or',\n",
       " 'inadequate',\n",
       " 'and',\n",
       " 'often',\n",
       " 'ambiguous',\n",
       " 'it',\n",
       " 'recommended',\n",
       " 'that',\n",
       " 'fulton',\n",
       " 'legislators',\n",
       " 'act',\n",
       " 'to',\n",
       " 'have',\n",
       " 'these',\n",
       " 'laws',\n",
       " 'studied',\n",
       " 'and',\n",
       " 'revised',\n",
       " 'to',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'modernizing',\n",
       " 'and',\n",
       " 'improving',\n",
       " 'them',\n",
       " 'the',\n",
       " 'grand',\n",
       " 'jury',\n",
       " 'commented',\n",
       " 'on',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'other',\n",
       " 'topics',\n",
       " 'among',\n",
       " 'them',\n",
       " 'the',\n",
       " 'atlanta',\n",
       " 'and',\n",
       " 'fulton',\n",
       " 'county',\n",
       " 'purchasing',\n",
       " 'departments',\n",
       " 'which',\n",
       " 'it',\n",
       " 'said',\n",
       " 'are',\n",
       " 'well',\n",
       " 'operated',\n",
       " 'and',\n",
       " 'follow',\n",
       " 'generally',\n",
       " 'accepted',\n",
       " 'practices',\n",
       " 'which',\n",
       " 'inure',\n",
       " 'to',\n",
       " 'the',\n",
       " 'best',\n",
       " 'interest',\n",
       " 'of',\n",
       " 'both',\n",
       " 'governments',\n",
       " 'merger',\n",
       " 'proposed',\n",
       " 'however',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'it',\n",
       " 'believes',\n",
       " 'these',\n",
       " 'two',\n",
       " 'offices',\n",
       " 'should',\n",
       " 'be',\n",
       " 'combined',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'greater',\n",
       " 'efficiency',\n",
       " 'and',\n",
       " 'reduce',\n",
       " 'the',\n",
       " 'cost',\n",
       " 'of',\n",
       " 'administration',\n",
       " 'the',\n",
       " 'city',\n",
       " 'purchasing',\n",
       " 'department',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'is',\n",
       " 'lacking',\n",
       " 'in',\n",
       " 'experienced',\n",
       " 'clerical',\n",
       " 'personnel',\n",
       " 'as',\n",
       " 'a',\n",
       " 'result',\n",
       " 'of',\n",
       " 'city',\n",
       " 'personnel',\n",
       " 'policies',\n",
       " 'it',\n",
       " 'urged',\n",
       " 'that',\n",
       " 'the',\n",
       " 'city',\n",
       " 'take',\n",
       " 'steps',\n",
       " 'to',\n",
       " 'remedy',\n",
       " 'this',\n",
       " 'problem',\n",
       " 'implementation',\n",
       " 'of',\n",
       " 'georgias',\n",
       " 'automobile',\n",
       " 'title',\n",
       " 'law',\n",
       " 'was',\n",
       " 'also',\n",
       " 'recommended',\n",
       " 'by',\n",
       " 'the',\n",
       " 'outgoing',\n",
       " 'jury',\n",
       " 'it',\n",
       " 'urged',\n",
       " 'that',\n",
       " 'the',\n",
       " 'next',\n",
       " 'legislature',\n",
       " 'provide',\n",
       " 'enabling',\n",
       " 'funds',\n",
       " 'and',\n",
       " 'reset',\n",
       " 'the',\n",
       " 'effective',\n",
       " 'date',\n",
       " 'so',\n",
       " 'that',\n",
       " 'an',\n",
       " 'orderly',\n",
       " 'implementation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'law',\n",
       " 'may',\n",
       " 'be',\n",
       " 'effected',\n",
       " 'the',\n",
       " 'grand',\n",
       " 'jury',\n",
       " 'took',\n",
       " 'a',\n",
       " 'swipe',\n",
       " 'at',\n",
       " 'the',\n",
       " 'state',\n",
       " 'welfare',\n",
       " 'departments',\n",
       " 'handling',\n",
       " 'of',\n",
       " 'federal',\n",
       " 'funds',\n",
       " 'granted',\n",
       " 'for',\n",
       " 'child',\n",
       " 'welfare',\n",
       " 'services',\n",
       " 'in',\n",
       " 'foster',\n",
       " 'homes',\n",
       " 'this',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'major',\n",
       " 'items',\n",
       " 'in',\n",
       " 'the',\n",
       " 'fulton',\n",
       " 'county',\n",
       " 'general',\n",
       " 'assistance',\n",
       " 'program',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'but',\n",
       " 'the',\n",
       " 'state',\n",
       " 'welfare',\n",
       " 'department',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'fit',\n",
       " 'to',\n",
       " 'distribute',\n",
       " 'these',\n",
       " 'funds',\n",
       " 'through',\n",
       " 'the',\n",
       " 'welfare',\n",
       " 'departments',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'counties',\n",
       " 'in',\n",
       " 'the',\n",
       " 'state',\n",
       " 'with',\n",
       " 'the',\n",
       " 'exception',\n",
       " 'of',\n",
       " 'fulton',\n",
       " 'county',\n",
       " 'which',\n",
       " 'receives',\n",
       " 'none',\n",
       " 'of',\n",
       " 'this',\n",
       " 'money',\n",
       " 'the',\n",
       " 'jurors',\n",
       " 'said',\n",
       " 'they',\n",
       " 'realize',\n",
       " 'a',\n",
       " 'proportionate',\n",
       " 'distribution',\n",
       " 'of',\n",
       " 'these',\n",
       " 'funds',\n",
       " 'might',\n",
       " 'disable',\n",
       " 'this',\n",
       " 'program',\n",
       " 'in',\n",
       " 'our',\n",
       " 'less',\n",
       " 'populous',\n",
       " 'counties',\n",
       " 'nevertheless',\n",
       " 'we',\n",
       " 'feel',\n",
       " 'that',\n",
       " 'in',\n",
       " 'the',\n",
       " 'future',\n",
       " 'fulton',\n",
       " 'county',\n",
       " 'should',\n",
       " 'receive',\n",
       " 'some',\n",
       " 'portion',\n",
       " 'of',\n",
       " 'these',\n",
       " 'available',\n",
       " 'funds',\n",
       " 'the',\n",
       " 'jurors',\n",
       " 'said',\n",
       " 'failure',\n",
       " 'to',\n",
       " 'do',\n",
       " 'this',\n",
       " 'will',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'place',\n",
       " 'a',\n",
       " 'disproportionate',\n",
       " 'burden',\n",
       " 'on',\n",
       " 'fulton',\n",
       " 'taxpayers',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'also',\n",
       " 'commented',\n",
       " 'on',\n",
       " 'the',\n",
       " 'fulton',\n",
       " 'ordinarys',\n",
       " 'court',\n",
       " 'which',\n",
       " 'has',\n",
       " 'been',\n",
       " 'under',\n",
       " 'fire',\n",
       " 'for',\n",
       " 'its',\n",
       " 'practices',\n",
       " 'in',\n",
       " 'the',\n",
       " 'appointment',\n",
       " 'of',\n",
       " 'appraisers',\n",
       " 'guardians',\n",
       " 'and',\n",
       " 'administrators',\n",
       " 'and',\n",
       " 'the',\n",
       " 'awarding',\n",
       " 'of',\n",
       " 'fees',\n",
       " 'and',\n",
       " 'compensation',\n",
       " 'wards',\n",
       " 'protected',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'it',\n",
       " 'found',\n",
       " 'the',\n",
       " 'court',\n",
       " 'has',\n",
       " 'incorporated',\n",
       " 'into',\n",
       " 'its',\n",
       " 'operating',\n",
       " 'procedures',\n",
       " 'the',\n",
       " 'recommendations',\n",
       " 'of',\n",
       " 'two',\n",
       " 'previous',\n",
       " 'grand',\n",
       " 'juries',\n",
       " 'the',\n",
       " 'atlanta',\n",
       " 'bar',\n",
       " 'association',\n",
       " 'and',\n",
       " 'an',\n",
       " 'interim',\n",
       " 'citizens',\n",
       " 'committee',\n",
       " 'these',\n",
       " 'actions',\n",
       " 'should',\n",
       " 'serve',\n",
       " 'to',\n",
       " 'protect',\n",
       " 'in',\n",
       " 'fact',\n",
       " 'and',\n",
       " 'in',\n",
       " 'effect',\n",
       " 'the',\n",
       " 'courts',\n",
       " 'wards',\n",
       " 'from',\n",
       " 'undue',\n",
       " 'costs',\n",
       " 'and',\n",
       " 'its',\n",
       " 'appointed',\n",
       " 'and',\n",
       " 'elected',\n",
       " 'servants',\n",
       " 'from',\n",
       " 'unmeritorious',\n",
       " 'criticisms',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'regarding',\n",
       " 'atlantas',\n",
       " 'new',\n",
       " 'multimilliondollar',\n",
       " 'airport',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'recommended',\n",
       " 'that',\n",
       " 'when',\n",
       " 'the',\n",
       " 'new',\n",
       " 'management',\n",
       " 'takes',\n",
       " 'charge',\n",
       " 'jan',\n",
       " 'the',\n",
       " 'airport',\n",
       " 'be',\n",
       " 'operated',\n",
       " 'in',\n",
       " 'a',\n",
       " 'manner',\n",
       " 'that',\n",
       " 'will',\n",
       " 'eliminate',\n",
       " 'political',\n",
       " 'influences',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'did',\n",
       " 'not',\n",
       " 'elaborate',\n",
       " 'but',\n",
       " 'it',\n",
       " 'added',\n",
       " 'that',\n",
       " 'there',\n",
       " 'should',\n",
       " 'be',\n",
       " 'periodic',\n",
       " 'surveillance',\n",
       " 'of',\n",
       " 'the',\n",
       " 'pricing',\n",
       " 'practices',\n",
       " 'of',\n",
       " 'the',\n",
       " 'concessionaires',\n",
       " 'for',\n",
       " 'the',\n",
       " 'purpose',\n",
       " 'of',\n",
       " 'keeping',\n",
       " 'the',\n",
       " 'prices',\n",
       " 'reasonable',\n",
       " 'ask',\n",
       " 'jail',\n",
       " 'deputies',\n",
       " 'on',\n",
       " 'other',\n",
       " 'matters',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'recommended',\n",
       " 'that',\n",
       " 'four',\n",
       " 'additional',\n",
       " 'deputies',\n",
       " 'be',\n",
       " 'employed',\n",
       " 'at',\n",
       " 'the',\n",
       " 'fulton',\n",
       " 'county',\n",
       " 'jail',\n",
       " 'and',\n",
       " 'a',\n",
       " 'doctor',\n",
       " 'medical',\n",
       " 'intern',\n",
       " 'or',\n",
       " 'extern',\n",
       " 'be',\n",
       " 'employed',\n",
       " 'for',\n",
       " 'night',\n",
       " 'and',\n",
       " 'weekend',\n",
       " 'duty',\n",
       " 'at',\n",
       " 'the',\n",
       " 'jail',\n",
       " 'fulton',\n",
       " 'legislators',\n",
       " 'work',\n",
       " 'with',\n",
       " 'city',\n",
       " 'officials',\n",
       " 'to',\n",
       " 'pass',\n",
       " 'enabling',\n",
       " 'legislation',\n",
       " 'that',\n",
       " 'will',\n",
       " 'permit',\n",
       " 'the',\n",
       " 'establishment',\n",
       " 'of',\n",
       " 'a',\n",
       " 'fair',\n",
       " 'and',\n",
       " 'equitable',\n",
       " 'pension',\n",
       " 'plan',\n",
       " 'for',\n",
       " 'city',\n",
       " 'employes',\n",
       " 'the',\n",
       " 'jury',\n",
       " 'praised',\n",
       " 'the',\n",
       " 'administration',\n",
       " 'and',\n",
       " 'operation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'atlanta',\n",
       " 'police',\n",
       " 'department',\n",
       " 'the',\n",
       " 'fulton',\n",
       " 'tax',\n",
       " 'commissioners',\n",
       " 'office',\n",
       " 'the',\n",
       " 'bellwood',\n",
       " 'and',\n",
       " 'alpharetta',\n",
       " 'prison',\n",
       " 'farms',\n",
       " 'grady',\n",
       " 'hospital',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fulton',\n",
       " 'health',\n",
       " 'department',\n",
       " 'mayor',\n",
       " 'william',\n",
       " 'b',\n",
       " 'hartsfield',\n",
       " 'filed',\n",
       " 'suit',\n",
       " 'for',\n",
       " 'divorce',\n",
       " 'from',\n",
       " 'his',\n",
       " 'wife',\n",
       " 'pearl',\n",
       " 'williams',\n",
       " 'hartsfield',\n",
       " 'in',\n",
       " 'fulton',\n",
       " 'superior',\n",
       " 'court',\n",
       " 'friday',\n",
       " 'his',\n",
       " 'petition',\n",
       " 'charged',\n",
       " 'mental',\n",
       " 'cruelty',\n",
       " 'the',\n",
       " 'couple',\n",
       " 'was',\n",
       " 'married',\n",
       " 'aug',\n",
       " 'they',\n",
       " 'have',\n",
       " 'a',\n",
       " 'son',\n",
       " 'william',\n",
       " 'berry',\n",
       " 'jr',\n",
       " 'and',\n",
       " 'a',\n",
       " 'daughter',\n",
       " 'mrs',\n",
       " 'j',\n",
       " 'm',\n",
       " 'cheshire',\n",
       " 'of',\n",
       " 'griffin',\n",
       " 'attorneys',\n",
       " 'for',\n",
       " 'the',\n",
       " 'mayor',\n",
       " 'said',\n",
       " 'that',\n",
       " 'an',\n",
       " 'amicable',\n",
       " 'property',\n",
       " 'settlement',\n",
       " 'has',\n",
       " 'been',\n",
       " 'agreed',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'petition',\n",
       " 'listed',\n",
       " 'the',\n",
       " 'mayors',\n",
       " 'occupation',\n",
       " 'as',\n",
       " 'attorney',\n",
       " 'and',\n",
       " 'his',\n",
       " 'age',\n",
       " 'as',\n",
       " 'it',\n",
       " 'listed',\n",
       " 'his',\n",
       " 'wifes',\n",
       " 'age',\n",
       " 'as',\n",
       " 'and',\n",
       " 'place',\n",
       " 'of',\n",
       " 'birth',\n",
       " 'as',\n",
       " 'opelika',\n",
       " 'ala',\n",
       " 'the',\n",
       " 'petition',\n",
       " 'said',\n",
       " 'that',\n",
       " 'the',\n",
       " 'couple',\n",
       " 'has',\n",
       " 'not',\n",
       " 'lived',\n",
       " 'together',\n",
       " 'as',\n",
       " 'man',\n",
       " 'and',\n",
       " 'wife',\n",
       " 'for',\n",
       " 'more',\n",
       " 'than',\n",
       " 'a',\n",
       " 'year',\n",
       " 'the',\n",
       " 'hartsfield',\n",
       " 'home',\n",
       " 'is',\n",
       " 'at',\n",
       " 'e',\n",
       " 'pelham',\n",
       " 'rd',\n",
       " 'aj',\n",
       " 'henry',\n",
       " 'l',\n",
       " 'bowden',\n",
       " 'was',\n",
       " 'listed',\n",
       " 'on',\n",
       " 'the',\n",
       " 'petition',\n",
       " 'as',\n",
       " 'the',\n",
       " 'mayors',\n",
       " 'attorney',\n",
       " 'hartsfield',\n",
       " 'has',\n",
       " 'been',\n",
       " 'mayor',\n",
       " 'of',\n",
       " 'atlanta',\n",
       " 'with',\n",
       " 'exception',\n",
       " 'of',\n",
       " 'one',\n",
       " 'brief',\n",
       " 'interlude',\n",
       " 'since',\n",
       " 'his',\n",
       " 'political',\n",
       " 'career',\n",
       " 'goes',\n",
       " 'back',\n",
       " 'to',\n",
       " 'his',\n",
       " 'election',\n",
       " 'to',\n",
       " 'city',\n",
       " 'council',\n",
       " 'in',\n",
       " 'the',\n",
       " 'mayors',\n",
       " 'present',\n",
       " 'term',\n",
       " 'of',\n",
       " 'office',\n",
       " 'expires',\n",
       " 'jan',\n",
       " 'he',\n",
       " 'will',\n",
       " 'be',\n",
       " 'succeeded',\n",
       " 'by',\n",
       " 'ivan',\n",
       " 'allen',\n",
       " 'jr',\n",
       " 'who',\n",
       " 'became',\n",
       " 'a',\n",
       " 'candidate',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sept',\n",
       " 'primary',\n",
       " 'after',\n",
       " 'mayor',\n",
       " 'hartsfield',\n",
       " 'announced',\n",
       " 'that',\n",
       " 'he',\n",
       " 'would',\n",
       " 'not',\n",
       " 'run',\n",
       " 'for',\n",
       " 'reelection',\n",
       " 'georgia',\n",
       " 'republicans',\n",
       " 'are',\n",
       " 'getting',\n",
       " 'strong',\n",
       " 'encouragement',\n",
       " 'to',\n",
       " 'enter',\n",
       " 'a',\n",
       " 'candidate',\n",
       " 'in',\n",
       " 'the',\n",
       " 'governors',\n",
       " 'race',\n",
       " 'a',\n",
       " 'top',\n",
       " 'official',\n",
       " 'said',\n",
       " 'wednesday',\n",
       " 'robert',\n",
       " 'snodgrass',\n",
       " 'state',\n",
       " 'gop',\n",
       " 'chairman',\n",
       " 'said',\n",
       " 'a',\n",
       " 'meeting',\n",
       " 'held',\n",
       " 'tuesday',\n",
       " 'night',\n",
       " 'in',\n",
       " 'blue',\n",
       " 'ridge',\n",
       " 'brought',\n",
       " 'enthusiastic',\n",
       " 'responses',\n",
       " 'from',\n",
       " 'the',\n",
       " 'audience',\n",
       " 'state',\n",
       " 'party',\n",
       " 'chairman',\n",
       " 'james',\n",
       " 'w',\n",
       " 'dorsey',\n",
       " 'added',\n",
       " 'that',\n",
       " 'enthusiasm',\n",
       " 'was',\n",
       " 'picking',\n",
       " 'up',\n",
       " 'for',\n",
       " 'a',\n",
       " 'state',\n",
       " 'rally',\n",
       " 'to',\n",
       " 'be',\n",
       " 'held',\n",
       " 'sept',\n",
       " 'in',\n",
       " 'savannah',\n",
       " 'at',\n",
       " 'which',\n",
       " 'newly',\n",
       " 'elected',\n",
       " 'texas',\n",
       " 'sen',\n",
       " 'john',\n",
       " 'tower',\n",
       " 'will',\n",
       " 'be',\n",
       " 'the',\n",
       " 'featured',\n",
       " 'speaker',\n",
       " 'in',\n",
       " 'the',\n",
       " 'blue',\n",
       " 'ridge',\n",
       " 'meeting',\n",
       " 'the',\n",
       " 'audience',\n",
       " 'was',\n",
       " 'warned',\n",
       " 'that',\n",
       " 'entering',\n",
       " 'a',\n",
       " 'candidate',\n",
       " 'for',\n",
       " 'governor',\n",
       " 'would',\n",
       " 'force',\n",
       " 'it',\n",
       " 'to',\n",
       " 'take',\n",
       " 'petitions',\n",
       " 'out',\n",
       " 'into',\n",
       " 'voting',\n",
       " 'precincts',\n",
       " 'to',\n",
       " 'obtain',\n",
       " 'the',\n",
       " 'signatures',\n",
       " 'of',\n",
       " 'registered',\n",
       " 'voters',\n",
       " 'despite',\n",
       " 'the',\n",
       " 'warning',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'unanimous',\n",
       " 'vote',\n",
       " 'to',\n",
       " 'enter',\n",
       " 'a',\n",
       " 'candidate',\n",
       " 'according',\n",
       " 'to',\n",
       " 'republicans',\n",
       " 'who',\n",
       " 'attended',\n",
       " 'when',\n",
       " 'the',\n",
       " 'crowd',\n",
       " 'was',\n",
       " 'asked',\n",
       " 'whether',\n",
       " 'it',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'wait',\n",
       " 'one',\n",
       " 'more',\n",
       " 'term',\n",
       " 'to',\n",
       " 'make',\n",
       " 'the',\n",
       " 'race',\n",
       " 'it',\n",
       " 'voted',\n",
       " 'no',\n",
       " 'and',\n",
       " 'there',\n",
       " 'were',\n",
       " 'no',\n",
       " 'dissents',\n",
       " 'the',\n",
       " 'largest',\n",
       " 'hurdle',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsampling frequent words\n",
    "from collections import Counter\n",
    "import random, math\n",
    "\n",
    "def subsample_frequent_words(corpus):\n",
    "    filtered_corpus = []\n",
    "    word_counts = dict(Counter(list(itertools.chain.from_iterable(corpus))))\n",
    "    sum_word_counts = sum(list(word_counts.values()))\n",
    "    word_counts = {word: word_counts[word]/float(sum_word_counts) for word in word_counts}\n",
    "    for text in corpus:\n",
    "        filtered_corpus.append([])\n",
    "        for word in text:\n",
    "            if random.random() < (1+math.sqrt(word_counts[word] * 1e3)) * 1e-3 / float(word_counts[word]):\n",
    "                filtered_corpus[-1].append(word)\n",
    "    return filtered_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = subsample_frequent_words(corpus)\n",
    "vocabulary = set(itertools.chain.from_iterable(corpus))\n",
    "\n",
    "word_to_index = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "index_to_word = {idx: w for (idx, w) in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 443768 pairs of target and context words\n"
     ]
    }
   ],
   "source": [
    "# build bag of words\n",
    "import numpy as np\n",
    "\n",
    "context_tuple_list = []\n",
    "w = 4\n",
    "\n",
    "for text in corpus:\n",
    "    for i, word in enumerate(text):\n",
    "        first_context_word_index = max(0,i-w)\n",
    "        last_context_word_index = min(i+w, len(text))\n",
    "        for j in range(first_context_word_index, last_context_word_index):\n",
    "            if i!=j:\n",
    "                context_tuple_list.append((word, text[j]))\n",
    "print(\"There are {} pairs of target and context words\".format(len(context_tuple_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fulton', 'county')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_tuple_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get batches\n",
    "import random\n",
    "\n",
    "def get_batches(context_tuple_list, batch_size=100):\n",
    "    random.shuffle(context_tuple_list)\n",
    "    batches = []\n",
    "    batch_target, batch_context, batch_negative = [], [], []\n",
    "    for i in range(len(context_tuple_list)):\n",
    "        batch_target.append(word_to_index[context_tuple_list[i][0]])\n",
    "        batch_context.append(word_to_index[context_tuple_list[i][1]])\n",
    "        batch_negative.append([word_to_index[w] for w in context_tuple_list[i][2]])\n",
    "        if (i+1) % batch_size == 0 or i == len(context_tuple_list)-1:\n",
    "            tensor_target = torch.from_numpy(np.array(batch_target)).long()\n",
    "            tensor_context = torch.from_numpy(np.array(batch_context)).long()\n",
    "            tensor_negative = torch.from_numpy(np.array(batch_negative)).long()\n",
    "            batches.append((tensor_target, tensor_context, tensor_negative))\n",
    "            batch_target, batch_context, batch_negative = [], [], []\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get negatie samples\n",
    "from numpy.random import multinomial\n",
    "\n",
    "def sample_negative(sample_size):\n",
    "    sample_probability = {}\n",
    "    word_counts = dict(Counter(list(itertools.chain.from_iterable(corpus))))\n",
    "    normalizing_factor = sum([v**0.75 for v in word_counts.values()])\n",
    "    for word in word_counts:\n",
    "        sample_probability[word] = word_counts[word]**0.75 / normalizing_factor\n",
    "    words = np.array(list(word_counts.keys()))\n",
    "    while True:\n",
    "        word_list = []\n",
    "        sampled_index = np.array(multinomial(sample_size, list(sample_probability.values())))\n",
    "        for index, count in enumerate(sampled_index):\n",
    "            for _ in range(count):\n",
    "                 word_list.append(words[index])\n",
    "        yield word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 443768 pairs of target and context words\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "context_tuple_list = []\n",
    "w = 4\n",
    "negative_samples = sample_negative(8)\n",
    "\n",
    "for text in corpus:\n",
    "    for i, word in enumerate(text):\n",
    "        first_context_word_index = max(0,i-w)\n",
    "        last_context_word_index = min(i+w, len(text))\n",
    "        for j in range(first_context_word_index, last_context_word_index):\n",
    "            if i!=j:\n",
    "                context_tuple_list.append((word, text[j], next(negative_samples)))\n",
    "print(\"There are {} pairs of target and context words\".format(len(context_tuple_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size,embedding_size):\n",
    "        super(Word2Vec,self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embeddings_target = nn.Embedding(vocab_size, embedding_size, sparse=True)\n",
    "        self.embeddings_context = nn.Embedding(vocab_size, embedding_size, sparse=True)\n",
    "        self.init_emb()\n",
    "        \n",
    "    def init_emb(self):\n",
    "        \"\"\"Initialize embedding weight like word2vec.\n",
    "        The u_embedding is a uniform distribution in [-0.5/em_size, 0.5/emb_size], and the elements of v_embedding are zeroes.\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        initrange = 0.5 / self.embedding_size\n",
    "        self.embeddings_target.weight.data.uniform_(-initrange, initrange)\n",
    "        self.embeddings_context.weight.data.uniform_(-0, 0)\n",
    "        \n",
    "    def forward(self, target_word, context_word, negative_example):\n",
    "        emb_target = self.embeddings_target(target_word)\n",
    "        emb_context = self.embeddings_context(context_word)\n",
    "        emb_product = torch.mul(emb_target, emb_context).squeeze()\n",
    "        emb_product = torch.sum(emb_product, dim=1)\n",
    "        out = torch.sum(F.logsigmoid(emb_product))\n",
    "        emb_negative = self.embeddings_context(negative_example)\n",
    "        emb_product = torch.bmm(emb_negative, emb_target.unsqueeze(2))\n",
    "        emb_product = torch.sum(emb_product, dim=1)\n",
    "        out += torch.sum(F.logsigmoid(-emb_product))\n",
    "        return -out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience=5, min_percent_gain=0.1):\n",
    "        self.patience = patience\n",
    "        self.loss_list = []\n",
    "        self.min_percent_gain = min_percent_gain / 100.\n",
    "        \n",
    "    def update_loss(self, loss):\n",
    "        self.loss_list.append(loss)\n",
    "        if len(self.loss_list) > self.patience:\n",
    "            del self.loss_list[0]\n",
    "    \n",
    "    def stop_training(self):\n",
    "        if len(self.loss_list) == 1:\n",
    "            return False\n",
    "        gain = (max(self.loss_list) - min(self.loss_list)) / max(self.loss_list)\n",
    "        print(\"Loss gain: {}%\".format(round(100*gain,2)))\n",
    "        if gain < self.min_percent_gain:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec(\n",
       "  (embeddings_target): Embedding(12132, 300, sparse=True)\n",
       "  (embeddings_context): Embedding(12132, 300, sparse=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "vocab_size = len(vocabulary)\n",
    "embedding_size = 300\n",
    "model = Word2Vec(vocab_size,embedding_size)\n",
    "# use gpu\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7279200"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the total parameters of model\n",
    "total_param  = []\n",
    "for p in model.parameters():\n",
    "    total_param.append(int(p.numel()))\n",
    "sum(total_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.025)\n",
    "early_stopping = EarlyStopping(patience=5, min_percent_gain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2443.624174650725\n",
      "Loss:  1973.07513482721\n",
      "Loss:  1887.940788750176\n",
      "Loss:  1850.3224124392948\n",
      "Loss:  1819.3338623046875\n",
      "Loss:  1786.5457466744087\n",
      "Loss:  1748.750718125352\n",
      "Loss:  1703.162789009713\n",
      "Loss:  1647.2410800693272\n",
      "Loss:  1579.1900167379292\n",
      "Loss:  1497.3632378105644\n",
      "Loss:  1402.6745528487472\n",
      "Loss:  1297.0658305400127\n",
      "Loss:  1185.3376717782235\n",
      "Loss:  1071.9927896035683\n",
      "Loss:  959.3160040228216\n",
      "Loss:  851.5809922776781\n",
      "Loss:  748.6580651085656\n",
      "Loss:  652.9136391029701\n",
      "Loss:  566.6815698297174\n",
      "Loss:  489.9911404171506\n",
      "Loss:  422.633557018933\n",
      "Loss:  364.29344809592305\n",
      "Loss:  314.5074945398279\n",
      "Loss:  272.5231519132047\n",
      "Loss:  237.43214849523596\n",
      "Loss:  207.77155022148614\n",
      "Loss:  182.97723113738738\n",
      "Loss:  161.8713275806324\n",
      "Loss:  144.56596340145077\n",
      "Loss:  129.89649561289195\n",
      "Loss:  117.32255093686216\n",
      "Loss:  106.513052931777\n",
      "Loss:  97.23506267650707\n",
      "Loss:  88.83453015164213\n",
      "Loss:  82.10582413544526\n",
      "Loss:  75.6556672792177\n",
      "Loss:  70.45898820688059\n",
      "Loss:  65.7153518264358\n",
      "Loss:  61.30426394832027\n",
      "Loss:  57.35779619646502\n",
      "Loss:  53.96383084477605\n",
      "Loss:  50.973293940226235\n",
      "Loss:  47.957556423840224\n",
      "Loss:  45.66610365515357\n",
      "Loss:  43.076210692122174\n",
      "Loss:  41.22840669992808\n",
      "Loss:  39.26428384179467\n",
      "Loss:  37.35252748094163\n",
      "Loss:  35.78572438214276\n",
      "Loss:  34.100205713564215\n",
      "Loss:  33.01808047079825\n",
      "Loss:  31.26781784091984\n",
      "Loss:  30.306997806102306\n",
      "Loss:  29.389880652900214\n",
      "Loss:  28.100589442897487\n",
      "Loss:  27.127080333125484\n",
      "Loss:  26.040910222508884\n",
      "Loss:  25.28718089198207\n",
      "Loss:  24.428832243154716\n",
      "Loss:  23.56103584358284\n",
      "Loss:  22.89894590291891\n",
      "Loss:  22.31572280918156\n",
      "Loss:  21.652240985148662\n",
      "Loss:  20.994285067996465\n",
      "Loss:  20.671608856132437\n",
      "Loss:  19.57658763404365\n",
      "Loss:  19.1587735768911\n",
      "Loss:  18.672128892159677\n",
      "Loss:  18.486904926128215\n",
      "Loss:  17.831201725177937\n",
      "Loss:  17.456921087728965\n",
      "Loss:  17.26821113706709\n",
      "Loss:  16.642002354871046\n",
      "Loss:  16.38057057921951\n",
      "Loss:  15.793330158199275\n",
      "Loss:  15.424992161828118\n",
      "Loss:  15.257362043535387\n",
      "Loss:  14.904771143251711\n",
      "Loss:  14.661315041619378\n",
      "Loss:  13.849013135239884\n",
      "Loss:  14.196991658425546\n",
      "Loss:  13.721524453377938\n",
      "Loss:  13.835480891906464\n",
      "Loss:  13.334107923078108\n",
      "Loss:  13.002966958123285\n",
      "Loss:  12.692605456790409\n",
      "Loss:  12.48607434453191\n",
      "Loss:  12.490554306958172\n",
      "Loss:  12.23696231412458\n",
      "Loss:  11.939555954288792\n",
      "Loss:  11.557226271242708\n",
      "Loss:  11.459840203190709\n",
      "Loss:  11.615528789726463\n",
      "Loss:  11.173700942649498\n",
      "Loss:  10.985227004901782\n",
      "Loss:  10.919432296409264\n",
      "Loss:  10.827883368139869\n",
      "Loss:  10.43466651332271\n",
      "Loss:  10.193803155744398\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "import time\n",
    "\n",
    "# Set model to train\n",
    "model.train()\n",
    "\n",
    "epochs = 100\n",
    "for i in range(epochs):\n",
    "    losses = []\n",
    "    context_tuple_batches = get_batches(context_tuple_list, batch_size=2000)\n",
    "    for i in range(len(context_tuple_batches)):\n",
    "        optimizer.zero_grad()\n",
    "        target_tensor, context_tensor, negative_tensor = context_tuple_batches[i]\n",
    "        target_tensor = Variable(target_tensor)\n",
    "        context_tensor = Variable(context_tensor)\n",
    "        negative_tensor = Variable(negative_tensor)\n",
    "        # use the gpu\n",
    "        target_tensor = target_tensor.cuda()\n",
    "        context_tensor = context_tensor.cuda()\n",
    "        negative_tensor = negative_tensor.cuda()\n",
    "        \n",
    "        loss = model(target_tensor, context_tensor, negative_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    print(\"Loss: \", np.mean(losses))\n",
    "    #early_stopping.update_loss(np.mean(losses))\n",
    "    #if early_stopping.stop_training():\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model.embeddings_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(12132, 300, sparse=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(12132, 300, sparse=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07422798,  0.00573754, -0.03458479, ..., -0.00224186,\n",
       "        -0.01031344, -0.00758016],\n",
       "       [ 0.28183687,  0.01303123, -0.02787262, ...,  0.38275105,\n",
       "         0.24691202,  0.0876765 ],\n",
       "       [-0.01674725, -0.02723128,  0.08544952, ..., -0.00305449,\n",
       "         0.07062403,  0.05459627],\n",
       "       ...,\n",
       "       [ 0.00252927,  0.05711698,  0.03951392, ...,  0.52196735,\n",
       "         0.38400954, -0.19426127],\n",
       "       [-0.07613605, -0.25332096, -0.1483818 , ...,  0.1908881 ,\n",
       "        -0.00184861, -0.02639896],\n",
       "       [-0.09747757, -0.19539762,  0.37105843, ...,  0.5234165 ,\n",
       "         0.23794156,  0.09051089]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
